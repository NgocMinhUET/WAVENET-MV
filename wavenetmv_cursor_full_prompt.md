# Cursor AI â€“ **Full Build Prompt** for *WAVENETâ€‘MV*

> **Goal:**â€¯Generate all source code, training scripts, and evaluation utilities for the singleâ€‘version WAVENETâ€‘MV framework (waveletâ€¯+â€¯AdaMixNet), ready to run on COCOâ€¯2017 (val) and DAVISâ€¯2017.\
> *Framework:* PyTorchÂ â‰¥Â 1.13â€¯+â€¯CompressAI.

---

## 0Â Â Project Skeleton

```
./
 â”œâ”€ models/
 â”‚Â Â  â”œâ”€ wavelet_transform_cnn.py     # detailed lifting CNN
 â”‚Â Â  â”œâ”€ adamixnet.py                 # adaptive mixing network
 â”‚Â Â  â”œâ”€ compressor_vnvc.py           # quant + entropy bottleneck
 â”‚Â Â  â””â”€ ai_heads.py                  # YOLOâ€‘tiny, SegFormerâ€‘lite
 â”œâ”€ training/
 â”‚Â Â  â”œâ”€ stage1_train_wavelet.py      # preâ€‘train lifting CNN (L2)
 â”‚Â Â  â”œâ”€ stage2_train_compressor.py   # rateâ€‘distortion training
 â”‚Â Â  â””â”€ stage3_train_ai.py           # compressedâ€‘domain AI heads
 â”œâ”€ evaluation/
 â”‚Â Â  â”œâ”€ codec_metrics.py             # PSNR Â· MSâ€‘SSIM Â· BPP
 â”‚Â Â  â”œâ”€ task_metrics.py              # mAP Â· IoU Â· Topâ€‘1
 â”‚Â Â  â””â”€ plot_rd_curves.py            # RD curves for paper
 â”œâ”€ datasets/  (scripts â†” COCO Â· DAVIS)
 â”œâ”€ fig/          (autoâ€‘saved plots)
 â”œâ”€ requirements.txt
 â”œâ”€ README.md    (run instructions)
 â””â”€ RESULTS.md   (autoâ€‘filled summary)
```

---

##

```
# Stageâ€‘0  (RGB â†’ feature)
Conv3x3  in=3   out=64  stride=1  pad=1   + ReLU

#=== Predict branch =======================================
# Predict highâ€‘freq residual  H = P(X)
PredictCNN â‰¡
   Conv3x3  64â†’64  s1 p1  + ReLU
   Conv3x3  64â†’64  s1 p1  + ReLU
   Conv1x1  64â†’Câ€²  s1 p0              âŸ¶  LH, HL, HH  (3Ã—Câ€²)

#=== Update branch ========================================
# Update lowâ€‘freq base  L = U(X,Â H)
UpdateCNN â‰¡
   [X â€– H]  (#Â concat along channel)
   Conv3x3  (64+3Câ€²)â†’64  + ReLU
   Conv3x3  64â†’64  + ReLU
   Conv1x1  64â†’Câ€²            âŸ¶  LL  (1Ã—Câ€²)

#=== Output ===============================================
Return  cat(LL,Â LH,Â HL,Â HH) â€ƒ# 4Ã—Câ€² channels
```

**Loss (Stageâ€‘1):**\
\(\mathcal L_{wavelet}=\|x-\hat{x}\|_2^2\)  using inverse lifting (shared transpose Convs).

### 1.2Â Â `AdaMixNet` Â (ğµ,â€¯4Câ€²,â€¯H,â€¯W)Â â†’Â (ğµ,â€¯C\_{mix},â€¯H,â€¯W)

*`Nâ€¯=â€¯4`*\* parallel filters, \**`C_{mix}=128`*

```
# Split input into N groups (or groupâ€‘conv)
for i = 1..N:
   Fi = Conv3x3  (4Câ€²/N)â†’(Câ€²/2)  + ReLU    # Multiâ€‘Conv filters

# Attention weights
AttCNN â‰¡
   Conv3x3  4Câ€²â†’64  + ReLU
   Conv1x1  64â†’N                  # logits â†’ Softmax across N
   wi(x) = Softmax(logits)_i

# Weighted mixing
Y(x) = Î£_i  wi(x) Â· Fi(x)

# Channel reduction (optional)
Conv1x1  (Câ€²/2)â†’C_{mix}
Return Y
```

### 1.3Â Â `CompressorVNVC` Â (ğµ,â€¯C\_{mix},â€¯H,â€¯W)Â â†’Â bitstream

- **Quantizer:** roundâ€‘withâ€‘noise.
- **Entropy model:** CompressAIÂ `GaussianConditional` (learned Ïƒ).
- **Loss (Stageâ€‘2):**\
  \(\mathcal L = \lambda\,\mathcal L_{rec} + \text{BPP}\),  Î»â€¯âˆˆâ€¯{256,â€¯512,â€¯1024}.

### 1.4Â Â `AIHeads`  (YOLOâ€‘tiny & SegFormerâ€‘lite)

- **Input:** decoded feature maps (float) without pixel recon.
- **Output:** detection boxes / seg masks / action logits.
- **Loss (Stageâ€‘3):** taskâ€‘specific + optional KD from pixelâ€‘domain teacher.

---

## 2Â Â Training Schedule

| Stage  | Script                        | Epochs | Trainable                    | Loss        |
| ------ | ----------------------------- | ------ | ---------------------------- | ----------- |
| Â 1Â Â Â Â  | Â `stage1_train_wavelet.py`    | Â 30    | WaveletCNN                   | Â Lâ‚‚Â recon   |
| Â 2Â Â Â Â  | Â `stage2_train_compressor.py` | Â 40    | Compressor (+freeze wavelet) | Â Î»Â·Lâ‚‚ + BPP |
| Â 3Â Â Â Â  | Â `stage3_train_ai.py`         | Â 50    | AIHeads (+freeze prev.)      | Â Task loss  |

Use Adam, LRÂ =â€¯2eâ€‘4 â†’ cosine decay; batchÂ =Â 8; seedÂ =Â 42.

---

## 3Â Â Evaluation & Reporting

1. **Codec metrics**: `codec_metrics.py`â€ƒâ†’Â CSV (BPP,Â PSNR,Â MSâ€‘SSIM)
2. **Task metrics**: `task_metrics.py`â€ƒâ†’Â CSV (mAP,Â IoU,Â Topâ€‘1)
3. **Plots**: `plot_rd_curves.py`â€ƒâ†’Â PDF & PNG in ./fig/
4. Autoâ€‘write `RESULTS.md` summarising tables & discussion.

---

## 4Â Â CodingÂ & Logging Rules

- PyTorch â‰¥1.13, TorchVision â‰¥0.14, CompressAIÂ â‰¥1.2.
- Use `torch.cuda.amp` mixedâ€‘precision.
- Each script logs to TensorBoard (`./runs/`).
- Raise `ValueError` for size mismatch; unitâ€‘test forward pass in `pytest`.

---

## 5Â Â BeginÂ ğŸ¡’

1. Generate folder tree & empty files.
2. Fill in `wavelet_transform_cnn.py` with the layerâ€‘exact architecture above.
3. Implement AdaMixNet as specified.
4. Write Compressor, AI heads, training scripts, evaluation utilities.
5. Populate `README.md` with installation & run commands.
6. Halt only when all TODO markers are resolved and `RESULTS.md` is created.

---

## 5  Validation Checklist (autoâ€‘run)

Before finishing, the pipeline must generate `` answering **YES / NO** for each item:

1. WaveletTransformCNN includes PredictCNN & UpdateCNN layers exactly (3Ã—3â€‘ReLUâ€‘3Ã—3â€‘ReLUâ€‘1Ã—1).
2. AdaMixNet implements 4 parallel conv branches **and** softmax attention mixing.
3. Compressor uses CompressAI `GaussianConditional`; Î» âˆˆ {256,â€¯512,â€¯1024}.
4. AI heads consume *compressed features* without pixel reconstruction.
5. All training scripts save checkpoints and TensorBoard logs.
6. Evaluation scripts output CSV + RDâ€‘plots under `./fig/`.
7. README contains dataset download and run commands.

`checklist_report.md` must be autoâ€‘generated by the final evaluation script and copied to the project root.

---

## 6  Dataset Setup Scripts

Create bash scripts inside `datasets/`:

```bash
# setup_coco.sh
mkdir -p datasets/COCO && cd datasets/COCO
wget http://images.cocodataset.org/zips/val2017.zip -O val2017.zip
unzip val2017.zip && rm val2017.zip
wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip -O ann.zip
unzip ann.zip && rm ann.zip
```

```bash
# setup_davis.sh
mkdir -p datasets/DAVIS && cd datasets/DAVIS
wget https://davischallenge.org/challenge2017/DAVIS-data/DAVIS-2017-trainval-480p.zip -O davis.zip
unzip davis.zip && rm davis.zip
```

Add to README:

```bash
bash datasets/setup_coco.sh
bash datasets/setup_davis.sh
```

---

## 7  Baseline Comparison Utilities

1. Implement `evaluation/compare_baselines.py`: â€¢ Decode WAVENETâ€‘MV bitstreams. â€¢ Decode HEVC and VVC (use `ffmpeg` or `x265`). â€¢ Load public DVC checkpoint. â€¢ Run same AI heads on each decoded input. â€¢ Produce a table:\
   `| Codec | BPP | PSNR | MSâ€‘SSIM | mAP | IoU | Latency |`\
   â€¢ Save as `baseline_comparison.csv`.
2. Provide helper shell script `hevc_encode.sh` to batchâ€‘encode sample MP4s via x265 at CRF=28.

---

## 8  Execution Order

1. **Generate** folder tree & stubs.
2. **Fill** `wavelet_transform_cnn.py`, `adamixnet.py`, `compressor_vnvc.py`, `ai_heads.py` per spec.
3. **Create** dataset setup scripts and add instructions to README.
4. **Write** training & evaluation scripts; ensure they call `checklist_report.md` generator.
5. **Run** minimal smokeâ€‘test (single batch) to validate forward pass.
6. **Stop** when `RESULTS.md`, `checklist_report.md`, and plots are present.

