"""
Script ƒë·ªÉ s·ª≠a l·ªói device mismatch gi·ªØa CUDA v√† CPU trong c√°c module PyTorch
L·ªói: "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
"""

import os
import sys
import torch
import torch.nn as nn
import importlib
import argparse

def fix_device_mismatch(model, device=None, verbose=True):
    """
    ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c tham s·ªë v√† buffers c·ªßa model ƒë·ªÅu ·ªü c√πng m·ªôt device
    
    Args:
        model: M√¥ h√¨nh PyTorch c·∫ßn s·ª≠a
        device: Device ƒë√≠ch (cuda ho·∫∑c cpu), n·∫øu None s·∫Ω t·ª± ƒë·ªông ch·ªçn cuda n·∫øu c√≥
        verbose: In th√¥ng b√°o chi ti·∫øt
    """
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    if verbose:
        print(f"üîß ƒêang chuy·ªÉn model sang device {device}...")
    
    # Chuy·ªÉn to√†n b·ªô model sang device
    model.to(device)
    
    # Ki·ªÉm tra t·ª´ng module con
    for name, module in model.named_modules():
        # ƒê·∫£m b·∫£o t·∫•t c·∫£ parameters ƒë·ªÅu ·ªü ƒë√∫ng device
        for param_name, param in module.named_parameters(recurse=False):
            if param.device != device:
                if verbose:
                    print(f"‚ö†Ô∏è Parameter {name}.{param_name} ƒëang ·ªü {param.device}, chuy·ªÉn sang {device}")
                param.data = param.data.to(device)
        
        # ƒê·∫£m b·∫£o t·∫•t c·∫£ buffers ƒë·ªÅu ·ªü ƒë√∫ng device
        for buffer_name, buffer in module.named_buffers(recurse=False):
            if buffer.device != device:
                if verbose:
                    print(f"‚ö†Ô∏è Buffer {name}.{buffer_name} ƒëang ·ªü {buffer.device}, chuy·ªÉn sang {device}")
                module.register_buffer(buffer_name, buffer.to(device))
    
    # Ki·ªÉm tra l·∫°i sau khi s·ª≠a
    mismatched_params = []
    mismatched_buffers = []
    
    for name, module in model.named_modules():
        for param_name, param in module.named_parameters(recurse=False):
            if param.device != device:
                mismatched_params.append(f"{name}.{param_name}")
        
        for buffer_name, buffer in module.named_buffers(recurse=False):
            if buffer.device != device:
                mismatched_buffers.append(f"{name}.{buffer_name}")
    
    if len(mismatched_params) == 0 and len(mismatched_buffers) == 0:
        if verbose:
            print(f"‚úÖ T·∫•t c·∫£ parameters v√† buffers ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang {device}")
        return True
    else:
        if verbose:
            if mismatched_params:
                print(f"‚ùå C√°c parameters sau v·∫´n ch∆∞a ·ªü {device}: {mismatched_params}")
            if mismatched_buffers:
                print(f"‚ùå C√°c buffers sau v·∫´n ch∆∞a ·ªü {device}: {mismatched_buffers}")
        return False

def fix_model_from_checkpoint(checkpoint_path, device=None, save_fixed=True):
    """
    S·ª≠a l·ªói device mismatch cho m·ªôt checkpoint
    
    Args:
        checkpoint_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file checkpoint
        device: Device ƒë√≠ch (cuda ho·∫∑c cpu)
        save_fixed: L∆∞u checkpoint ƒë√£ s·ª≠a
    """
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    print(f"üîç ƒêang ki·ªÉm tra checkpoint: {checkpoint_path}")
    
    try:
        # T·∫£i checkpoint
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        print("‚úÖ ƒê√£ t·∫£i checkpoint th√†nh c√¥ng")
        
        # Ki·ªÉm tra c·∫•u tr√∫c checkpoint
        if isinstance(checkpoint, dict):
            fixed_count = 0
            
            # X·ª≠ l√Ω t·ª´ng state_dict trong checkpoint
            for key in checkpoint.keys():
                if isinstance(checkpoint[key], dict) and any(k.endswith('.weight') or k.endswith('.bias') for k in checkpoint[key].keys()):
                    print(f"üîß ƒêang x·ª≠ l√Ω state_dict: {key}")
                    state_dict = checkpoint[key]
                    
                    # Ki·ªÉm tra v√† s·ª≠a device cho t·ª´ng tensor
                    for param_name, param in state_dict.items():
                        if isinstance(param, torch.Tensor) and param.device != device:
                            state_dict[param_name] = param.to(device)
                            fixed_count += 1
                    
                    print(f"‚úÖ ƒê√£ s·ª≠a {fixed_count} tensors trong {key}")
            
            if fixed_count > 0 and save_fixed:
                # T·∫°o t√™n file m·ªõi
                base, ext = os.path.splitext(checkpoint_path)
                fixed_path = f"{base}_fixed{ext}"
                
                # L∆∞u checkpoint ƒë√£ s·ª≠a
                torch.save(checkpoint, fixed_path)
                print(f"üíæ ƒê√£ l∆∞u checkpoint ƒë√£ s·ª≠a: {fixed_path}")
            
            return fixed_count
        else:
            print("‚ùå Checkpoint kh√¥ng c√≥ c·∫•u tr√∫c dictionary nh∆∞ mong ƒë·ª£i")
            return 0
    except Exception as e:
        print(f"‚ùå L·ªói khi x·ª≠ l√Ω checkpoint: {e}")
        return 0

def fix_model_in_evaluation(model_name, checkpoint_path, device=None):
    """
    T·∫£i v√† s·ª≠a model ƒë·ªÉ s·ª≠ d·ª•ng trong evaluation
    
    Args:
        model_name: T√™n c·ªßa class model (v√≠ d·ª•: "WaveletTransformCNN")
        checkpoint_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file checkpoint
        device: Device ƒë√≠ch (cuda ho·∫∑c cpu)
    """
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    try:
        # T√¨m module ch·ª©a model
        module_found = False
        model_class = None
        
        for module_name in ['models.wavelet_transform_cnn', 'models.adamixnet', 'models.compressor_vnvc', 'models.compressor_improved', 'models.ai_heads']:
            try:
                module = importlib.import_module(module_name)
                if hasattr(module, model_name):
                    model_class = getattr(module, model_name)
                    module_found = True
                    print(f"‚úÖ T√¨m th·∫•y class {model_name} trong module {module_name}")
                    break
            except ImportError:
                continue
        
        if not module_found:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y class {model_name} trong c√°c module")
            return None
        
        # T·∫°o instance c·ªßa model
        model = model_class()
        
        # T·∫£i checkpoint
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # T√¨m state_dict ph√π h·ª£p
        state_dict_key = None
        for key in checkpoint.keys():
            if key.lower().endswith('state_dict') and model_name.lower() in key.lower():
                state_dict_key = key
                break
        
        if state_dict_key is None:
            # Th·ª≠ t√¨m state_dict b·∫•t k·ª≥
            for key in checkpoint.keys():
                if key.lower().endswith('state_dict'):
                    state_dict_key = key
                    break
        
        if state_dict_key is not None:
            # Load state_dict
            model.load_state_dict(checkpoint[state_dict_key])
            print(f"‚úÖ ƒê√£ t·∫£i state_dict t·ª´ key: {state_dict_key}")
        else:
            print("‚ùå Kh√¥ng t√¨m th·∫•y state_dict ph√π h·ª£p trong checkpoint")
            return None
        
        # S·ª≠a device mismatch
        fix_device_mismatch(model, device)
        
        return model
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫£i v√† s·ª≠a model: {e}")
        return None

def fix_all_models_in_checkpoint(checkpoint_path, device=None):
    """
    S·ª≠a t·∫•t c·∫£ c√°c models trong m·ªôt checkpoint
    
    Args:
        checkpoint_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file checkpoint
        device: Device ƒë√≠ch (cuda ho·∫∑c cpu)
    """
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    try:
        # Import c√°c models
        from models.wavelet_transform_cnn import WaveletTransformCNN
        from models.adamixnet import AdaMixNet
        try:
            from models.compressor_improved import ImprovedMultiLambdaCompressorVNVC as MultiLambdaCompressorVNVC
        except ImportError:
            from models.compressor_vnvc import MultiLambdaCompressorVNVC
        
        # T·∫£i checkpoint
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        print(f"‚úÖ ƒê√£ t·∫£i checkpoint: {checkpoint_path}")
        
        # Kh·ªüi t·∫°o models
        wavelet_cnn = WaveletTransformCNN(input_channels=3, feature_channels=64, wavelet_channels=64)
        adamixnet = AdaMixNet(input_channels=256, C_prime=64, C_mix=128)
        compressor = MultiLambdaCompressorVNVC(input_channels=128, latent_channels=192)
        
        # Load state dicts
        if 'wavelet_state_dict' in checkpoint:
            wavelet_cnn.load_state_dict(checkpoint['wavelet_state_dict'])
            print("‚úÖ ƒê√£ t·∫£i wavelet_state_dict")
        
        if 'adamixnet_state_dict' in checkpoint:
            adamixnet.load_state_dict(checkpoint['adamixnet_state_dict'])
            print("‚úÖ ƒê√£ t·∫£i adamixnet_state_dict")
        
        if 'compressor_state_dict' in checkpoint:
            compressor.load_state_dict(checkpoint['compressor_state_dict'])
            print("‚úÖ ƒê√£ t·∫£i compressor_state_dict")
        
        # S·ª≠a device mismatch
        print("\nüîß ƒêang s·ª≠a WaveletTransformCNN...")
        fix_device_mismatch(wavelet_cnn, device)
        
        print("\nüîß ƒêang s·ª≠a AdaMixNet...")
        fix_device_mismatch(adamixnet, device)
        
        print("\nüîß ƒêang s·ª≠a MultiLambdaCompressorVNVC...")
        fix_device_mismatch(compressor, device)
        
        # L∆∞u checkpoint ƒë√£ s·ª≠a
        checkpoint['wavelet_state_dict'] = wavelet_cnn.state_dict()
        checkpoint['adamixnet_state_dict'] = adamixnet.state_dict()
        checkpoint['compressor_state_dict'] = compressor.state_dict()
        
        # T·∫°o t√™n file m·ªõi
        base, ext = os.path.splitext(checkpoint_path)
        fixed_path = f"{base}_fixed_deep{ext}"
        
        # L∆∞u checkpoint ƒë√£ s·ª≠a
        torch.save(checkpoint, fixed_path)
        print(f"\nüíæ ƒê√£ l∆∞u checkpoint ƒë√£ s·ª≠a: {fixed_path}")
        
        return fixed_path
    except Exception as e:
        print(f"‚ùå L·ªói khi s·ª≠a models: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    parser = argparse.ArgumentParser(description="S·ª≠a l·ªói device mismatch trong checkpoint PyTorch")
    parser.add_argument("--checkpoint", type=str, required=True, help="ƒê∆∞·ªùng d·∫´n ƒë·∫øn file checkpoint")
    parser.add_argument("--device", type=str, default=None, help="Device ƒë√≠ch (cuda ho·∫∑c cpu)")
    parser.add_argument("--mode", type=str, default="deep", choices=["simple", "deep"], help="Ch·∫ø ƒë·ªô s·ª≠a (simple: ch·ªâ s·ª≠a tensors, deep: s·ª≠a to√†n b·ªô models)")
    
    args = parser.parse_args()
    
    # X√°c ƒë·ªãnh device
    if args.device:
        device = torch.device(args.device)
    else:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    print(f"üöÄ B·∫Øt ƒë·∫ßu s·ª≠a l·ªói device mismatch v·ªõi device={device}, mode={args.mode}")
    
    if args.mode == "simple":
        # Ch·∫ø ƒë·ªô ƒë∆°n gi·∫£n: ch·ªâ s·ª≠a tensors
        fixed_count = fix_model_from_checkpoint(args.checkpoint, device)
        print(f"‚úÖ ƒê√£ s·ª≠a {fixed_count} tensors")
    else:
        # Ch·∫ø ƒë·ªô s√¢u: s·ª≠a to√†n b·ªô models
        fixed_path = fix_all_models_in_checkpoint(args.checkpoint, device)
        if fixed_path:
            print(f"‚úÖ ƒê√£ s·ª≠a to√†n b·ªô models v√† l∆∞u v√†o: {fixed_path}")
            print(f"\nüöÄ ƒê·ªÅ xu·∫•t ch·∫°y l·ªánh sau ƒë·ªÉ ki·ªÉm tra:")
            print(f"python evaluation/codec_metrics.py --checkpoint {fixed_path} --dataset coco --data_dir datasets/COCO --split val --lambdas 128 --batch_size 1 --max_samples 10 --output_csv results/test_fixed.csv")
        else:
            print("‚ùå Kh√¥ng th·ªÉ s·ª≠a models")

if __name__ == "__main__":
    main() 