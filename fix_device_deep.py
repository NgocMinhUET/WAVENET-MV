"""
Script Ä‘á»ƒ sá»­a lá»—i device mismatch giá»¯a CUDA vÃ  CPU trong cÃ¡c module PyTorch
Lá»—i: "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
"""

import os
import sys
import torch
import torch.nn as nn
import importlib
import argparse

def fix_device_mismatch(model, device=None, verbose=True):
    """
    Äáº£m báº£o táº¥t cáº£ cÃ¡c tham sá»‘ vÃ  buffers cá»§a model Ä‘á»u á»Ÿ cÃ¹ng má»™t device
    
    Args:
        model: MÃ´ hÃ¬nh PyTorch cáº§n sá»­a
        device: Device Ä‘Ã­ch (cuda hoáº·c cpu), náº¿u None sáº½ tá»± Ä‘á»™ng chá»n cuda náº¿u cÃ³
        verbose: In thÃ´ng bÃ¡o chi tiáº¿t
    """
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    if verbose:
        print(f"ğŸ”§ Äang chuyá»ƒn model sang device {device}...")
    
    # Chuyá»ƒn toÃ n bá»™ model sang device
    model.to(device)
    
    # Kiá»ƒm tra tá»«ng module con
    for name, module in model.named_modules():
        # Äáº£m báº£o táº¥t cáº£ parameters Ä‘á»u á»Ÿ Ä‘Ãºng device
        for param_name, param in module.named_parameters(recurse=False):
            if param.device != device:
                if verbose:
                    print(f"âš ï¸ Parameter {name}.{param_name} Ä‘ang á»Ÿ {param.device}, chuyá»ƒn sang {device}")
                param.data = param.data.to(device)
        
        # Äáº£m báº£o táº¥t cáº£ buffers Ä‘á»u á»Ÿ Ä‘Ãºng device
        for buffer_name, buffer in module.named_buffers(recurse=False):
            if buffer.device != device:
                if verbose:
                    print(f"âš ï¸ Buffer {name}.{buffer_name} Ä‘ang á»Ÿ {buffer.device}, chuyá»ƒn sang {device}")
                module.register_buffer(buffer_name, buffer.to(device))
    
    # Kiá»ƒm tra láº¡i sau khi sá»­a
    mismatched_params = []
    mismatched_buffers = []
    
    for name, module in model.named_modules():
        for param_name, param in module.named_parameters(recurse=False):
            if param.device != device:
                mismatched_params.append(f"{name}.{param_name}")
        
        for buffer_name, buffer in module.named_buffers(recurse=False):
            if buffer.device != device:
                mismatched_buffers.append(f"{name}.{buffer_name}")
    
    if len(mismatched_params) == 0 and len(mismatched_buffers) == 0:
        if verbose:
            print(f"âœ… Táº¥t cáº£ parameters vÃ  buffers Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn sang {device}")
        return True
    else:
        if verbose:
            if mismatched_params:
                print(f"âŒ CÃ¡c parameters sau váº«n chÆ°a á»Ÿ {device}: {mismatched_params}")
            if mismatched_buffers:
                print(f"âŒ CÃ¡c buffers sau váº«n chÆ°a á»Ÿ {device}: {mismatched_buffers}")
        return False

def fix_model_from_checkpoint(checkpoint_path, device=None, save_fixed=True):
    """
    Sá»­a lá»—i device mismatch cho má»™t checkpoint
    
    Args:
        checkpoint_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file checkpoint
        device: Device Ä‘Ã­ch (cuda hoáº·c cpu)
        save_fixed: LÆ°u checkpoint Ä‘Ã£ sá»­a
    """
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    print(f"ğŸ” Äang kiá»ƒm tra checkpoint: {checkpoint_path}")
    
    try:
        # Táº£i checkpoint
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        print("âœ… ÄÃ£ táº£i checkpoint thÃ nh cÃ´ng")
        
        # Kiá»ƒm tra cáº¥u trÃºc checkpoint
        if isinstance(checkpoint, dict):
            fixed_count = 0
            
            # Xá»­ lÃ½ tá»«ng state_dict trong checkpoint
            for key in checkpoint.keys():
                if isinstance(checkpoint[key], dict) and any(k.endswith('.weight') or k.endswith('.bias') for k in checkpoint[key].keys()):
                    print(f"ğŸ”§ Äang xá»­ lÃ½ state_dict: {key}")
                    state_dict = checkpoint[key]
                    
                    # Kiá»ƒm tra vÃ  sá»­a device cho tá»«ng tensor
                    for param_name, param in state_dict.items():
                        if isinstance(param, torch.Tensor) and param.device != device:
                            state_dict[param_name] = param.to(device)
                            fixed_count += 1
                    
                    print(f"âœ… ÄÃ£ sá»­a {fixed_count} tensors trong {key}")
            
            if fixed_count > 0 and save_fixed:
                # Táº¡o tÃªn file má»›i
                base, ext = os.path.splitext(checkpoint_path)
                fixed_path = f"{base}_fixed{ext}"
                
                # LÆ°u checkpoint Ä‘Ã£ sá»­a
                torch.save(checkpoint, fixed_path)
                print(f"ğŸ’¾ ÄÃ£ lÆ°u checkpoint Ä‘Ã£ sá»­a: {fixed_path}")
            
            return fixed_count
        else:
            print("âŒ Checkpoint khÃ´ng cÃ³ cáº¥u trÃºc dictionary nhÆ° mong Ä‘á»£i")
            return 0
    except Exception as e:
        print(f"âŒ Lá»—i khi xá»­ lÃ½ checkpoint: {e}")
        return 0

def fix_model_in_evaluation(model_name, checkpoint_path, device=None):
    """
    Táº£i vÃ  sá»­a model Ä‘á»ƒ sá»­ dá»¥ng trong evaluation
    
    Args:
        model_name: TÃªn cá»§a class model (vÃ­ dá»¥: "WaveletTransformCNN")
        checkpoint_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file checkpoint
        device: Device Ä‘Ã­ch (cuda hoáº·c cpu)
    """
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    try:
        # TÃ¬m module chá»©a model
        module_found = False
        model_class = None
        
        for module_name in ['models.wavelet_transform_cnn', 'models.adamixnet', 'models.compressor_vnvc', 'models.compressor_improved', 'models.ai_heads']:
            try:
                module = importlib.import_module(module_name)
                if hasattr(module, model_name):
                    model_class = getattr(module, model_name)
                    module_found = True
                    print(f"âœ… TÃ¬m tháº¥y class {model_name} trong module {module_name}")
                    break
            except ImportError:
                continue
        
        if not module_found:
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y class {model_name} trong cÃ¡c module")
            return None
        
        # Táº¡o instance cá»§a model
        model = model_class()
        
        # Táº£i checkpoint
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # TÃ¬m state_dict phÃ¹ há»£p
        state_dict_key = None
        for key in checkpoint.keys():
            if key.lower().endswith('state_dict') and model_name.lower() in key.lower():
                state_dict_key = key
                break
        
        if state_dict_key is None:
            # Thá»­ tÃ¬m state_dict báº¥t ká»³
            for key in checkpoint.keys():
                if key.lower().endswith('state_dict'):
                    state_dict_key = key
                    break
        
        if state_dict_key is not None:
            # Load state_dict
            model.load_state_dict(checkpoint[state_dict_key])
            print(f"âœ… ÄÃ£ táº£i state_dict tá»« key: {state_dict_key}")
        else:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y state_dict phÃ¹ há»£p trong checkpoint")
            return None
        
        # Sá»­a device mismatch
        fix_device_mismatch(model, device)
        
        return model
    except Exception as e:
        print(f"âŒ Lá»—i khi táº£i vÃ  sá»­a model: {e}")
        return None

def fix_all_models_in_checkpoint(checkpoint_path, device=None):
    """
    Sá»­a táº¥t cáº£ cÃ¡c models trong má»™t checkpoint
    
    Args:
        checkpoint_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file checkpoint
        device: Device Ä‘Ã­ch (cuda hoáº·c cpu)
    """
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    try:
        # Import cÃ¡c models
        from models.wavelet_transform_cnn import WaveletTransformCNN
        from models.adamixnet import AdaMixNet
        try:
            from models.compressor_improved import ImprovedMultiLambdaCompressorVNVC as MultiLambdaCompressorVNVC
        except ImportError:
            from models.compressor_vnvc import MultiLambdaCompressorVNVC
        
        # Táº£i checkpoint
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        print(f"âœ… ÄÃ£ táº£i checkpoint: {checkpoint_path}")
        
        # Khá»Ÿi táº¡o models
        wavelet_cnn = WaveletTransformCNN(input_channels=3, feature_channels=64, wavelet_channels=64)
        adamixnet = AdaMixNet(input_channels=256, C_prime=64, C_mix=128)
        compressor = MultiLambdaCompressorVNVC(input_channels=128, latent_channels=192)
        
        # Load state dicts
        if 'wavelet_state_dict' in checkpoint:
            wavelet_cnn.load_state_dict(checkpoint['wavelet_state_dict'])
            print("âœ… ÄÃ£ táº£i wavelet_state_dict")
        
        if 'adamixnet_state_dict' in checkpoint:
            adamixnet.load_state_dict(checkpoint['adamixnet_state_dict'])
            print("âœ… ÄÃ£ táº£i adamixnet_state_dict")
        
        if 'compressor_state_dict' in checkpoint:
            compressor.load_state_dict(checkpoint['compressor_state_dict'])
            print("âœ… ÄÃ£ táº£i compressor_state_dict")
        
        # Sá»­a device mismatch
        print("\nğŸ”§ Äang sá»­a WaveletTransformCNN...")
        fix_device_mismatch(wavelet_cnn, device)
        
        print("\nğŸ”§ Äang sá»­a AdaMixNet...")
        fix_device_mismatch(adamixnet, device)
        
        print("\nğŸ”§ Äang sá»­a MultiLambdaCompressorVNVC...")
        fix_device_mismatch(compressor, device)
        
        # LÆ°u checkpoint Ä‘Ã£ sá»­a
        checkpoint['wavelet_state_dict'] = wavelet_cnn.state_dict()
        checkpoint['adamixnet_state_dict'] = adamixnet.state_dict()
        checkpoint['compressor_state_dict'] = compressor.state_dict()
        
        # Táº¡o tÃªn file má»›i
        base, ext = os.path.splitext(checkpoint_path)
        fixed_path = f"{base}_fixed_deep{ext}"
        
        # LÆ°u checkpoint Ä‘Ã£ sá»­a
        torch.save(checkpoint, fixed_path)
        print(f"\nğŸ’¾ ÄÃ£ lÆ°u checkpoint Ä‘Ã£ sá»­a: {fixed_path}")
        
        return fixed_path
    except Exception as e:
        print(f"âŒ Lá»—i khi sá»­a models: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    parser = argparse.ArgumentParser(description="Sá»­a lá»—i device mismatch trong checkpoint PyTorch")
    parser.add_argument("--checkpoint", type=str, required=True, help="ÄÆ°á»ng dáº«n Ä‘áº¿n file checkpoint")
    parser.add_argument("--device", type=str, default=None, help="Device Ä‘Ã­ch (cuda hoáº·c cpu)")
    parser.add_argument("--mode", type=str, default="deep", choices=["simple", "deep"], help="Cháº¿ Ä‘á»™ sá»­a (simple: chá»‰ sá»­a tensors, deep: sá»­a toÃ n bá»™ models)")
    
    args = parser.parse_args()
    
    # XÃ¡c Ä‘á»‹nh device
    if args.device:
        device = torch.device(args.device)
    else:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    print(f"ğŸš€ Báº¯t Ä‘áº§u sá»­a lá»—i device mismatch vá»›i device={device}, mode={args.mode}")
    
    if args.mode == "simple":
        # Cháº¿ Ä‘á»™ Ä‘Æ¡n giáº£n: chá»‰ sá»­a tensors
        fixed_count = fix_model_from_checkpoint(args.checkpoint, device)
        print(f"âœ… ÄÃ£ sá»­a {fixed_count} tensors")
    else:
        # Cháº¿ Ä‘á»™ sÃ¢u: sá»­a toÃ n bá»™ models
        fixed_path = fix_all_models_in_checkpoint(args.checkpoint, device)
        if fixed_path:
            print(f"âœ… ÄÃ£ sá»­a toÃ n bá»™ models vÃ  lÆ°u vÃ o: {fixed_path}")
            print(f"\nğŸš€ Äá» xuáº¥t cháº¡y lá»‡nh sau Ä‘á»ƒ kiá»ƒm tra:")
            print(f"python evaluation/codec_metrics.py --checkpoint {fixed_path} --dataset coco --data_dir datasets/COCO --split val --lambdas 128 --batch_size 1 --max_samples 10 --output_csv results/test_fixed.csv")
        else:
            print("âŒ KhÃ´ng thá»ƒ sá»­a models")

if __name__ == "__main__":
    main() 