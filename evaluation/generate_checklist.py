"""
Generate Validation Checklist Report
Tá»± Ä‘á»™ng verify táº¥t cáº£ requirements theo specification
"""

import os
import sys
import inspect
import torch
import importlib.util
from pathlib import Path
from datetime import datetime

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))


def check_file_exists(filepath):
    """Check if file exists"""
    return os.path.exists(filepath)


def check_wavelet_architecture():
    """Check WaveletTransformCNN architecture"""
    try:
        from models.wavelet_transform_cnn import WaveletTransformCNN, PredictCNN, UpdateCNN
        
        # Check PredictCNN layers
        predict_cnn = PredictCNN()
        predict_layers = predict_cnn.predict_layers
        
        # Should have: Conv3x3â†’Conv3x3â†’Conv1x1
        expected_layers = ['Conv2d', 'ReLU', 'Conv2d', 'ReLU', 'Conv2d']
        actual_layers = [type(layer).__name__ for layer in predict_layers]
        
        predict_correct = all(exp in actual for exp, actual in zip(expected_layers, actual_layers))
        
        # Check UpdateCNN layers
        update_cnn = UpdateCNN()
        update_layers = update_cnn.update_layers
        
        # Should have: Conv3x3â†’Conv3x3â†’Conv1x1
        update_correct = len(update_layers) >= 5  # Convâ†’ReLUâ†’Convâ†’ReLUâ†’Conv
        
        # Check main class
        model = WaveletTransformCNN()
        has_predict = hasattr(model, 'predict_cnn')
        has_update = hasattr(model, 'update_cnn')
        
        return predict_correct and update_correct and has_predict and has_update
        
    except Exception as e:
        return False


def check_adamixnet_architecture():
    """Check AdaMixNet architecture"""
    try:
        from models.adamixnet import AdaMixNet
        
        model = AdaMixNet(input_channels=256, C_prime=64, C_mix=128, N=4)
        
        # Check parallel filters
        has_parallel_filters = hasattr(model, 'parallel_filters')
        correct_num_filters = len(model.parallel_filters) == 4 if has_parallel_filters else False
        
        # Check attention mechanism
        has_attention = hasattr(model, 'attention_cnn')
        
        # Test forward pass
        x = torch.randn(1, 256, 32, 32)
        try:
            output = model(x)
            correct_output_shape = output.shape == (1, 128, 32, 32)
        except:
            correct_output_shape = False
        
        # Check attention weights method
        has_attention_method = hasattr(model, 'get_attention_weights')
        
        return (has_parallel_filters and correct_num_filters and 
                has_attention and correct_output_shape and has_attention_method)
        
    except Exception as e:
        return False


def check_compressor_gaussianconditional():
    """Check CompressorVNVC uses GaussianConditional"""
    try:
        from models.compressor_vnvc import CompressorVNVC, MultiLambdaCompressorVNVC
        
        # Check single compressor
        compressor = CompressorVNVC()
        has_entropy_bottleneck = hasattr(compressor, 'entropy_bottleneck')
        
        # Check entropy bottleneck has GaussianConditional
        if has_entropy_bottleneck:
            entropy_bottleneck = compressor.entropy_bottleneck
            has_gaussian = hasattr(entropy_bottleneck, 'gaussian_conditional')
        else:
            has_gaussian = False
        
        # Check multi-lambda support
        multi_compressor = MultiLambdaCompressorVNVC()
        has_lambda_support = hasattr(multi_compressor, 'set_lambda')
        
        # Check lambda values
        supported_lambdas = ['256', '512', '1024']
        correct_lambdas = all(lambda_val in multi_compressor.compressors for lambda_val in supported_lambdas)
        
        return has_entropy_bottleneck and has_gaussian and has_lambda_support and correct_lambdas
        
    except Exception as e:
        return False


def check_ai_heads_compressed_features():
    """Check AI heads consume compressed features"""
    try:
        from models.ai_heads import YOLOTinyHead, SegFormerLiteHead
        
        # Check YOLO head
        yolo_head = YOLOTinyHead(input_channels=128)
        has_feature_adapter = hasattr(yolo_head, 'feature_adapter')
        
        # Test forward pass
        compressed_features = torch.randn(1, 128, 32, 32)
        try:
            yolo_output = yolo_head(compressed_features)
            yolo_works = yolo_output.shape[0] == 1  # Batch size preserved
        except:
            yolo_works = False
        
        # Check SegFormer head
        segformer_head = SegFormerLiteHead(input_channels=128)
        has_segformer_adapter = hasattr(segformer_head, 'feature_adapter')
        
        try:
            segformer_output = segformer_head(compressed_features)
            segformer_works = segformer_output.shape[0] == 1
        except:
            segformer_works = False
        
        return (has_feature_adapter and yolo_works and 
                has_segformer_adapter and segformer_works)
        
    except Exception as e:
        return False


def check_training_scripts():
    """Check training scripts save checkpoints and logs"""
    training_scripts = [
        'training/stage1_train_wavelet.py',
        'training/stage2_train_compressor.py', 
        'training/stage3_train_ai.py'
    ]
    
    all_exist = all(check_file_exists(script) for script in training_scripts)
    
    # Check if scripts contain logging code
    has_logging = True
    for script in training_scripts:
        if check_file_exists(script):
            with open(script, 'r') as f:
                content = f.read()
                # Check for TensorBoard vÃ  checkpoint saving
                has_tensorboard = 'SummaryWriter' in content or 'tensorboard' in content
                has_checkpoint = 'torch.save' in content or 'checkpoint' in content
                if not (has_tensorboard and has_checkpoint):
                    has_logging = False
                    break
    
    return all_exist and has_logging


def check_evaluation_outputs():
    """Check evaluation scripts output CSV and plots"""
    eval_scripts = [
        'evaluation/codec_metrics.py',
        'evaluation/task_metrics.py',
        'evaluation/plot_rd_curves.py'
    ]
    
    all_exist = all(check_file_exists(script) for script in eval_scripts)
    
    # Check CSV output capability
    has_csv_output = True
    for script in eval_scripts:
        if check_file_exists(script):
            with open(script, 'r') as f:
                content = f.read()
                if 'csv' not in content.lower() and 'pandas' not in content:
                    has_csv_output = False
                    break
    
    # Check plot generation
    has_plot_capability = check_file_exists('evaluation/plot_rd_curves.py')
    if has_plot_capability:
        with open('evaluation/plot_rd_curves.py', 'r') as f:
            content = f.read()
            has_matplotlib = 'matplotlib' in content or 'plt' in content
    else:
        has_matplotlib = False
    
    return all_exist and has_csv_output and has_matplotlib


def check_readme_commands():
    """Check README has dataset download and run commands"""
    if not check_file_exists('README.md'):
        return False
        
    with open('README.md', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Check dataset setup commands
    has_dataset_setup = ('setup_coco.sh' in content and 'setup_davis.sh' in content)
    
    # Check training commands
    has_training_commands = ('stage1_train_wavelet.py' in content and 
                           'stage2_train_compressor.py' in content and
                           'stage3_train_ai.py' in content)
    
    # Check evaluation commands
    has_eval_commands = ('codec_metrics.py' in content and 'task_metrics.py' in content)
    
    return has_dataset_setup and has_training_commands and has_eval_commands


def generate_checklist_report():
    """Generate complete checklist report"""
    
    print("ğŸ” Generating WAVENET-MV Validation Checklist Report...")
    print("=" * 60)
    
    # Run all checks
    checks = [
        ("WaveletTransformCNN includes PredictCNN & UpdateCNN layers exactly", check_wavelet_architecture),
        ("AdaMixNet implements 4 parallel conv branches and softmax attention mixing", check_adamixnet_architecture),
        ("Compressor uses CompressAI GaussianConditional; Î» âˆˆ {256, 512, 1024}", check_compressor_gaussianconditional),
        ("AI heads consume compressed features without pixel reconstruction", check_ai_heads_compressed_features),
        ("All training scripts save checkpoints and TensorBoard logs", check_training_scripts),
        ("Evaluation scripts output CSV + RD-plots under ./fig/", check_evaluation_outputs),
        ("README contains dataset download and run commands", check_readme_commands)
    ]
    
    results = []
    for description, check_func in checks:
        try:
            result = check_func()
            status = "âœ… YES" if result else "âŒ NO"
            results.append((description, status, result))
            print(f"{status} - {description}")
        except Exception as e:
            results.append((description, f"âŒ ERROR: {str(e)}", False))
            print(f"âŒ ERROR - {description}: {str(e)}")
    
    print("=" * 60)
    
    # Generate markdown report
    report_content = f"""# WAVENET-MV Validation Checklist Report

**Generated on:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## Architecture Validation

"""
    
    for i, (description, status, result) in enumerate(results, 1):
        report_content += f"{i}. **{description}**\n"
        report_content += f"   - Status: {status}\n\n"
    
    # Summary
    passed_checks = sum(1 for _, _, result in results if result)
    total_checks = len(results)
    
    report_content += f"""## Summary

- **Total Checks:** {total_checks}
- **Passed:** {passed_checks}
- **Failed:** {total_checks - passed_checks}
- **Success Rate:** {(passed_checks/total_checks)*100:.1f}%

"""
    
    if passed_checks == total_checks:
        report_content += "ğŸ‰ **All validation checks PASSED!** Framework is ready for use.\n"
    else:
        report_content += "âš ï¸ **Some validation checks FAILED.** Please review and fix the issues above.\n"
    
    report_content += f"""
## File Structure Verification

```
WAVENET-MV/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ wavelet_transform_cnn.py {'âœ…' if check_file_exists('models/wavelet_transform_cnn.py') else 'âŒ'}
â”‚   â”œâ”€â”€ adamixnet.py {'âœ…' if check_file_exists('models/adamixnet.py') else 'âŒ'}
â”‚   â”œâ”€â”€ compressor_vnvc.py {'âœ…' if check_file_exists('models/compressor_vnvc.py') else 'âŒ'}
â”‚   â””â”€â”€ ai_heads.py {'âœ…' if check_file_exists('models/ai_heads.py') else 'âŒ'}
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ stage1_train_wavelet.py {'âœ…' if check_file_exists('training/stage1_train_wavelet.py') else 'âŒ'}
â”‚   â”œâ”€â”€ stage2_train_compressor.py {'âœ…' if check_file_exists('training/stage2_train_compressor.py') else 'âŒ'}
â”‚   â””â”€â”€ stage3_train_ai.py {'âœ…' if check_file_exists('training/stage3_train_ai.py') else 'âŒ'}
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ codec_metrics.py {'âœ…' if check_file_exists('evaluation/codec_metrics.py') else 'âŒ'}
â”‚   â”œâ”€â”€ task_metrics.py {'âœ…' if check_file_exists('evaluation/task_metrics.py') else 'âŒ'}
â”‚   â””â”€â”€ plot_rd_curves.py {'âœ…' if check_file_exists('evaluation/plot_rd_curves.py') else 'âŒ'}
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ setup_coco.sh {'âœ…' if check_file_exists('datasets/setup_coco.sh') else 'âŒ'}
â”‚   â”œâ”€â”€ setup_davis.sh {'âœ…' if check_file_exists('datasets/setup_davis.sh') else 'âŒ'}
â”‚   â””â”€â”€ dataset_loaders.py {'âœ…' if check_file_exists('datasets/dataset_loaders.py') else 'âŒ'}
â”œâ”€â”€ requirements.txt {'âœ…' if check_file_exists('requirements.txt') else 'âŒ'}
â”œâ”€â”€ README.md {'âœ…' if check_file_exists('README.md') else 'âŒ'}
â””â”€â”€ PROJECT_CONTEXT.md {'âœ…' if check_file_exists('PROJECT_CONTEXT.md') else 'âŒ'}
```

---
*This report was auto-generated by the WAVENET-MV validation system.*
"""
    
    # Save report
    with open('checklist_report.md', 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"\nâœ… Checklist report saved to: checklist_report.md")
    print(f"ğŸ“Š Results: {passed_checks}/{total_checks} checks passed")
    
    return passed_checks == total_checks


if __name__ == "__main__":
    success = generate_checklist_report()
    sys.exit(0 if success else 1) 