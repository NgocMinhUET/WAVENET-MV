"""
Codec Metrics Evaluation - Final Version
Ph√π h·ª£p v·ªõi c·∫•u tr√∫c checkpoint th·ª±c t·∫ø:
- Stage 1: WaveletTransformCNN
- Stage 2: CompressorVNVC (kh√¥ng c√≥ AdaMixNet)
- Stage 3: AI Heads
"""

import os
import sys
import argparse
import torch
import torch.nn.functional as F
import numpy as np
import pandas as pd
from torch.utils.data import DataLoader
from tqdm import tqdm
from skimage.metrics import structural_similarity as ssim
from skimage.metrics import peak_signal_noise_ratio as psnr
import cv2
from pathlib import Path
import math

# Fix OpenMP warning
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

from models.wavelet_transform_cnn import WaveletTransformCNN
from models.adamixnet import AdaMixNet  
from models.compressor_vnvc import MultiLambdaCompressorVNVC
from datasets.dataset_loaders import COCODatasetLoader, DAVISDatasetLoader


def calculate_psnr(img1, img2, max_val=1.0):
    """Calculate PSNR gi·ªØa hai ·∫£nh."""
    if max_val == 1.0:
        data_max = torch.max(img1)
        data_min = torch.min(img1)
        max_val_est = max(data_max.abs(), data_min.abs())
        max_val = torch.clamp(max_val_est, min=1.0).item()
    mse = torch.mean((img1 - img2) ** 2)
    if mse == 0:
        return float('inf')
    return 20 * torch.log10(max_val / torch.sqrt(mse))


def calculate_ms_ssim(img1, img2, data_range=1.0):
    """Calculate MS-SSIM between two images with safe handling for small images."""
    if data_range == 1.0:
        data_max = torch.max(img1) if torch.is_tensor(img1) else np.max(img1)
        data_min = torch.min(img1) if torch.is_tensor(img1) else np.min(img1)
        data_range = max(abs(float(data_max)), abs(float(data_min)), 1.0)
    
    if torch.is_tensor(img1):
        img1 = img1.cpu().numpy()
    if torch.is_tensor(img2):
        img2 = img2.cpu().numpy()
    
    def safe_ssim(im1, im2, data_range):
        """Safe SSIM calculation with adaptive window size"""
        try:
            # Get image dimensions
            H, W = im1.shape[:2] if im1.ndim >= 2 else im1.shape
            
            # Calculate adaptive window size
            min_dim = min(H, W)
            if min_dim < 7:
                # For very small images, use smaller window or fallback to simple similarity
                if min_dim < 3:
                    # Fallback to simple correlation for tiny images
                    return np.corrcoef(im1.flatten(), im2.flatten())[0, 1]
                else:
                    # Use smaller window size
                    win_size = min_dim if min_dim % 2 == 1 else min_dim - 1
                    return ssim(im1, im2, data_range=data_range, win_size=win_size)
            else:
                # Normal case: use default window size
                return ssim(im1, im2, data_range=data_range)
        except Exception as e:
            # Fallback to simple correlation if SSIM fails
            print(f"SSIM failed, using correlation fallback: {e}")
            return np.corrcoef(im1.flatten(), im2.flatten())[0, 1]
    
    if img1.ndim == 4:
        ms_ssim_values = []
        for i in range(img1.shape[0]):
            im1 = np.transpose(img1[i], (1, 2, 0))
            im2 = np.transpose(img2[i], (1, 2, 0))
            
            if im1.shape[2] == 3:
                ms_ssim_val = 0
                for c in range(3):
                    ms_ssim_val += safe_ssim(im1[:,:,c], im2[:,:,c], data_range)
                ms_ssim_val /= 3
            else:
                ms_ssim_val = safe_ssim(im1.squeeze(), im2.squeeze(), data_range)
            
            ms_ssim_values.append(ms_ssim_val)
        
        return np.mean(ms_ssim_values)
    else:
        if img1.ndim == 3:
            img1 = np.transpose(img1, (1, 2, 0))
            img2 = np.transpose(img2, (1, 2, 0))
        
        return safe_ssim(img1, img2, data_range)


def estimate_bpp_from_features(quantized_features, image_shape):
    """Estimate BPP t·ª´ quantized feature dimensions."""
    B, C, H_feat, W_feat = quantized_features.shape
    compression_ratio = (H_feat * W_feat) / (image_shape[0] * image_shape[1])
    bits_per_feature = 4.0
    estimated_bpp = compression_ratio * C * bits_per_feature
    estimated_bpp = max(0.1, min(10.0, estimated_bpp))
    return estimated_bpp


class CodecEvaluatorFinal:
    """Evaluator cu·ªëi c√πng - ph√π h·ª£p v·ªõi c·∫•u tr√∫c checkpoint th·ª±c t·∫ø"""
    
    def __init__(self, args):
        self.args = args
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # Load models theo c·∫•u tr√∫c th·ª±c t·∫ø
        self.load_models_final()
        
        # Setup dataset
        self.setup_dataset()
        
        # Results storage
        self.results = []
        
    def load_models_final(self):
        """Load models theo c·∫•u tr√∫c checkpoint th·ª±c t·∫ø"""
        print("Loading models with actual checkpoint structure...")
        
        # Initialize models
        self.wavelet_cnn = WaveletTransformCNN(
            input_channels=3,
            feature_channels=64,
            wavelet_channels=64
        ).to(self.device)
        
        # AdaMixNet - s·ª≠ d·ª•ng random weights v√¨ kh√¥ng c√≥ trong checkpoint
        self.adamixnet = AdaMixNet(
            input_channels=256,
            C_prime=64,
            C_mix=128
        ).to(self.device)
        
        # S·ª≠ d·ª•ng CompressorVNVC ƒë∆°n gi·∫£n thay v√¨ MultiLambdaCompressorVNVC
        from models.compressor_vnvc import CompressorVNVC
        self.compressor = CompressorVNVC(
            input_channels=128,
            latent_channels=192,
            lambda_rd=128
        ).to(self.device)
        
        # Load WaveletTransformCNN t·ª´ Stage 1
        print("Loading WaveletTransformCNN from Stage 1...")
        if os.path.exists(self.args.stage1_checkpoint):
            stage1_checkpoint = torch.load(self.args.stage1_checkpoint, map_location=self.device)
            print(f"Stage 1 checkpoint keys: {list(stage1_checkpoint.keys())}")
            
            # Th·ª≠ c√°c key kh√°c nhau
            if 'wavelet_state_dict' in stage1_checkpoint:
                self.wavelet_cnn.load_state_dict(stage1_checkpoint['wavelet_state_dict'])
                print("‚úì Loaded wavelet_state_dict")
            elif 'model_state_dict' in stage1_checkpoint:
                self.wavelet_cnn.load_state_dict(stage1_checkpoint['model_state_dict'])
                print("‚úì Loaded model_state_dict for wavelet")
            elif 'state_dict' in stage1_checkpoint:
                self.wavelet_cnn.load_state_dict(stage1_checkpoint['state_dict'])
                print("‚úì Loaded state_dict for wavelet")
            else:
                print("‚ö†Ô∏è Using random weights for wavelet")
        else:
            print("‚ö†Ô∏è Stage 1 checkpoint not found, using random weights")
        
        # AdaMixNet - s·ª≠ d·ª•ng random weights
        print("AdaMixNet: Using random weights (not in checkpoints)")
        
        # Load CompressorVNVC t·ª´ Stage 2
        print("Loading CompressorVNVC from Stage 2...")
        if os.path.exists(self.args.stage2_checkpoint):
            stage2_checkpoint = torch.load(self.args.stage2_checkpoint, map_location=self.device)
            print(f"Stage 2 checkpoint keys: {list(stage2_checkpoint.keys())}")
            
            # Ki·ªÉm tra c·∫•u tr√∫c compressor trong checkpoint
            if 'compressor_state_dict' in stage2_checkpoint:
                checkpoint_keys = list(stage2_checkpoint['compressor_state_dict'].keys())
                print(f"Compressor checkpoint keys (first 10): {checkpoint_keys[:10]}")
                
                # T·∫°o model ph√π h·ª£p v·ªõi c·∫•u tr√∫c checkpoint
                if 'analysis_transform.conv1.weight' in checkpoint_keys:
                    # Checkpoint c√≥ c·∫•u tr√∫c v·ªõi conv1, norm1, skip_conv
                    print("Detected checkpoint with conv1/norm1 structure")
                    from models.compressor_improved import ImprovedCompressorVNVC
                    self.compressor = ImprovedCompressorVNVC(
                        input_channels=128,
                        latent_channels=192,
                        lambda_rd=128
                    ).to(self.device)
                else:
                    # Checkpoint c√≥ c·∫•u tr√∫c ƒë∆°n gi·∫£n
                    print("Detected checkpoint with simple structure")
                    from models.compressor_vnvc import CompressorVNVC
                    self.compressor = CompressorVNVC(
                        input_channels=128,
                        latent_channels=192,
                        lambda_rd=128
                    ).to(self.device)
                
                # Load state dict
                try:
                    self.compressor.load_state_dict(stage2_checkpoint['compressor_state_dict'])
                    print("‚úì Loaded compressor_state_dict successfully")
                except Exception as e:
                    print(f"‚ö†Ô∏è Failed to load compressor: {e}")
                    print("‚ö†Ô∏è Using random weights for compressor")
            elif 'state_dict' in stage2_checkpoint:
                self.compressor.load_state_dict(stage2_checkpoint['state_dict'])
                print("‚úì Loaded state_dict for compressor")
            else:
                print("‚ö†Ô∏è Using random weights for compressor")
        else:
            print("‚ö†Ô∏è Stage 2 checkpoint not found, using random weights")
        
        # Force move to device
        self.wavelet_cnn = self.force_move_to_device(self.wavelet_cnn, self.device)
        self.adamixnet = self.force_move_to_device(self.adamixnet, self.device)
        self.compressor = self.force_move_to_device(self.compressor, self.device)
        
        # Set to evaluation mode
        self.wavelet_cnn.eval()
        self.adamixnet.eval()
        self.compressor.eval()
        
        print("‚úì All models loaded successfully")
    
    def force_move_to_device(self, model, device):
        """Force move model to device"""
        print(f"üöÄ Force moving {model.__class__.__name__} to {device}")
        model = model.to(device)
        
        # Move all parameters
        for name, param in model.named_parameters():
            if param.device != device:
                param.data = param.data.to(device)
        
        # Move all buffers - ch·ªâ x·ª≠ l√Ω buffers kh√¥ng c√≥ d·∫•u ch·∫•m
        for name, buffer in model.named_buffers():
            if hasattr(buffer, 'device') and buffer.device != device:
                # Ch·ªâ x·ª≠ l√Ω buffers c√≥ t√™n ƒë∆°n gi·∫£n (kh√¥ng c√≥ d·∫•u ch·∫•m)
                if '.' not in name:
                    try:
                        model.register_buffer(name, buffer.to(device))
                    except Exception as e:
                        print(f"‚ö†Ô∏è Warning: Could not move buffer {name}: {e}")
        
        return model
    
    def setup_dataset(self):
        """Setup evaluation dataset"""
        if self.args.dataset == 'coco':
            dataset = COCODatasetLoader(
                data_dir=self.args.data_dir,
                subset=self.args.split,
                image_size=self.args.image_size,
                augmentation=False
            )
        elif self.args.dataset == 'davis':
            dataset = DAVISDatasetLoader(
                data_dir=self.args.data_dir,
                subset=self.args.split,
                image_size=self.args.image_size,
                augmentation=False
            )
        else:
            raise ValueError(f"Unsupported dataset: {self.args.dataset}")
        
        self.dataloader = DataLoader(
            dataset,
            batch_size=self.args.batch_size,
            shuffle=False,
            num_workers=0,
            pin_memory=False
        )
        
        print(f"‚úì Dataset loaded: {len(dataset)} images")
        
    def evaluate_lambda(self, lambda_value):
        """Evaluate metrics for specific lambda value"""
        print(f"\nEvaluating Œª = {lambda_value}")
        
        # Set compressor lambda (n·∫øu c√≥ method set_lambda)
        if hasattr(self.compressor, 'set_lambda'):
            self.compressor.set_lambda(lambda_value)
        else:
            # N·∫øu kh√¥ng c√≥, t·∫°o compressor m·ªõi v·ªõi lambda m·ªõi
            from models.compressor_vnvc import CompressorVNVC
            self.compressor = CompressorVNVC(
                input_channels=128,
                latent_channels=192,
                lambda_rd=lambda_value
            ).to(self.device)
            self.compressor.eval()
        
        # ƒê·∫£m b·∫£o t·∫•t c·∫£ models ƒë·ªÅu ·ªü ƒë√∫ng device TR∆Ø·ªöC KHI b·∫Øt ƒë·∫ßu evaluation
        self.ensure_models_on_device()
        
        # Ki·ªÉm tra device consistency tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu
        self.check_device_consistency()
        
        # Enable gradient checkpointing ƒë·ªÉ gi·∫£m memory usage
        if hasattr(self.wavelet_cnn, 'gradient_checkpointing_enable'):
            self.wavelet_cnn.gradient_checkpointing_enable()
        if hasattr(self.adamixnet, 'gradient_checkpointing_enable'):
            self.adamixnet.gradient_checkpointing_enable()
        if hasattr(self.compressor, 'gradient_checkpointing_enable'):
            self.compressor.gradient_checkpointing_enable()
        
        # Metrics accumulation
        psnr_values = []
        ms_ssim_values = []
        bpp_values = []
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(tqdm(self.dataloader, desc=f'Œª={lambda_value}')):
                # Get images v√† ƒë·∫£m b·∫£o ·ªü ƒë√∫ng device
                if isinstance(batch, dict):
                    images = batch['image']
                else:
                    images = batch[0]
                
                # ƒê·∫£m b·∫£o images ·ªü ƒë√∫ng device v√† dtype
                images = images.to(self.device, dtype=torch.float32, non_blocking=True)
                
                # Ki·ªÉm tra GPU memory usage m·ªói 100 batches
                if batch_idx % 100 == 0 and hasattr(torch.cuda, 'memory_allocated'):
                    memory_allocated = torch.cuda.memory_allocated() / 1024**3  # GB
                    memory_reserved = torch.cuda.memory_reserved() / 1024**3  # GB
                    print(f"üìä Batch {batch_idx}: GPU Memory - Allocated: {memory_allocated:.2f}GB, Reserved: {memory_reserved:.2f}GB")
                    
                    # N·∫øu memory usage qu√° cao, force clear cache
                    if memory_allocated > 0.8 * torch.cuda.get_device_properties(0).total_memory / 1024**3:
                        print("‚ö†Ô∏è High GPU memory usage detected, clearing cache...")
                        torch.cuda.empty_cache()
                
                # Debug info cho batch ƒë·∫ßu ti√™n
                if batch_idx == 0:
                    print(f"üîç Batch 0 debug:")
                    print(f"  - Input images: {images.shape}, device={images.device}, dtype={images.dtype}")
                    print(f"  - Input range: [{images.min():.4f}, {images.max():.4f}]")
                
                try:
                    # ƒê·∫£m b·∫£o models v·∫´n ·ªü ƒë√∫ng device tr∆∞·ªõc m·ªói forward pass
                    self.ensure_models_on_device()
                    
                    # Forward pass through pipeline
                    wavelet_coeffs = self.wavelet_cnn(images)
                    mixed_features = self.adamixnet(wavelet_coeffs)
                    x_hat, likelihoods, y_quantized = self.compressor(mixed_features)
                    
                    # Debug info cho batch ƒë·∫ßu ti√™n
                    if batch_idx == 0:
                        print(f"  - Wavelet output: {wavelet_coeffs.shape}, device={wavelet_coeffs.device}")
                        print(f"  - Wavelet range: [{wavelet_coeffs.min():.4f}, {wavelet_coeffs.max():.4f}]")
                        print(f"  - Mixed features: {mixed_features.shape}, device={mixed_features.device}")
                        print(f"  - Mixed range: [{mixed_features.min():.4f}, {mixed_features.max():.4f}]")
                        print(f"  - Compressor output: {x_hat.shape}, device={x_hat.device}")
                        print(f"  - X_hat range: [{x_hat.min():.4f}, {x_hat.max():.4f}]")
                        print(f"  - Y quantized: {y_quantized.shape}, device={y_quantized.device}")
                        print(f"  - Y quantized range: [{y_quantized.min():.4f}, {y_quantized.max():.4f}]")
                        print(f"  - Y quantized non-zero ratio: {(y_quantized != 0).float().mean():.4f}")
                        
                        # Ki·ªÉm tra likelihoods
                        if likelihoods is not None:
                            print(f"  - Likelihoods shape: {likelihoods.shape if hasattr(likelihoods, 'shape') else 'None'}")
                            if hasattr(likelihoods, 'shape'):
                                print(f"  - Likelihoods range: [{likelihoods.min():.4f}, {likelihoods.max():.4f}]")
                    
                    # Inverse transforms
                    recovered_coeffs = self.adamixnet.inverse_transform(x_hat)
                    reconstructed_images = self.wavelet_cnn.inverse_transform(recovered_coeffs)
                    
                    # Ensure same size
                    if reconstructed_images.shape != images.shape:
                        reconstructed_images = F.interpolate(
                            reconstructed_images, 
                            size=images.shape[2:], 
                            mode='bilinear', 
                            align_corners=False
                        )
                    
                    # Calculate metrics
                    for i in range(images.size(0)):
                        original = images[i:i+1]
                        reconstructed = reconstructed_images[i:i+1]
                        
                        psnr_val = calculate_psnr(original, reconstructed).item()
                        psnr_values.append(psnr_val)
                        
                        ms_ssim_val = calculate_ms_ssim(original, reconstructed)
                        ms_ssim_values.append(ms_ssim_val)
                        
                        bpp_val = estimate_bpp_from_features(y_quantized, images.shape[2:])
                        bpp_values.append(bpp_val)
                
                except Exception as e:
                    error_msg = str(e)
                    if "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same" in error_msg:
                        print(f"üö® Device mismatch detected at batch {batch_idx}! Forcing models to device...")
                        # Force move all models to device immediately
                        self.wavelet_cnn = self.wavelet_cnn.to(self.device)
                        self.adamixnet = self.adamixnet.to(self.device)
                        self.compressor = self.compressor.to(self.device)
                        
                        # Force move all parameters
                        for model in [self.wavelet_cnn, self.adamixnet, self.compressor]:
                            for param in model.parameters():
                                param.data = param.data.to(self.device, non_blocking=True)
                        
                        # Clear GPU cache
                        if hasattr(torch.cuda, 'empty_cache'):
                            torch.cuda.empty_cache()
                        
                        print(f"‚úÖ Models forced to {self.device}, retrying batch {batch_idx}...")
                        continue
                    else:
                        print(f"Error processing batch {batch_idx}: {e}")
                        continue
                
                # Early stop for quick testing
                if self.args.max_samples and batch_idx * self.args.batch_size >= self.args.max_samples:
                    break
        
        # Calculate average metrics
        avg_psnr = np.mean(psnr_values) if psnr_values else 0
        avg_ms_ssim = np.mean(ms_ssim_values) if ms_ssim_values else 0
        avg_bpp = np.mean(bpp_values) if bpp_values else 0
        
        return {
            'lambda': lambda_value,
            'psnr_db': avg_psnr,
            'ms_ssim': avg_ms_ssim,
            'bpp': avg_bpp,
            'num_samples': len(psnr_values)
        }
    
    def ensure_models_on_device(self):
        """ƒê·∫£m b·∫£o t·∫•t c·∫£ models ƒë·ªÅu ·ªü ƒë√∫ng device tr∆∞·ªõc forward pass"""
        # Ki·ªÉm tra v√† di chuy·ªÉn t·ª´ng model n·∫øu c·∫ßn
        for model_name, model in [('wavelet', self.wavelet_cnn), 
                                 ('adamixnet', self.adamixnet), 
                                 ('compressor', self.compressor)]:
            
            # Force move model to device
            model = model.to(self.device)
            
            # ƒê·∫£m b·∫£o t·∫•t c·∫£ parameters ƒë·ªÅu ƒë∆∞·ª£c di chuy·ªÉn
            for name, param in model.named_parameters():
                if param.device != self.device:
                    param.data = param.data.to(self.device, non_blocking=True)
            
            # ƒê·∫£m b·∫£o t·∫•t c·∫£ buffers ƒë·ªÅu ƒë∆∞·ª£c di chuy·ªÉn
            for name, buffer in model.named_buffers():
                if hasattr(buffer, 'device') and buffer.device != self.device:
                    try:
                        # S·ª≠ d·ª•ng register_buffer ƒë·ªÉ tr√°nh l·ªói v·ªõi buffer names c√≥ d·∫•u ch·∫•m
                        if '.' not in name:
                            model.register_buffer(name, buffer.to(self.device, non_blocking=True))
                    except Exception as e:
                        # N·∫øu kh√¥ng th·ªÉ register, ch·ªâ c·∫ßn ƒë·∫£m b·∫£o buffer ·ªü ƒë√∫ng device
                        pass
            
            # Set model to eval mode
            model.eval()
            
            # Force garbage collection ƒë·ªÉ gi·∫£i ph√≥ng memory
            if hasattr(torch.cuda, 'empty_cache'):
                torch.cuda.empty_cache()
    
    def check_device_consistency(self):
        """Ki·ªÉm tra device consistency c·ªßa t·∫•t c·∫£ models v√† in th√¥ng tin debug"""
        print(f"\nüîç Checking device consistency...")
        print(f"Target device: {self.device}")
        
        models_info = [
            ('WaveletTransformCNN', self.wavelet_cnn),
            ('AdaMixNet', self.adamixnet),
            ('CompressorVNVC', self.compressor)
        ]
        
        all_consistent = True
        for name, model in models_info:
            # Ki·ªÉm tra parameters
            param_devices = set()
            for param_name, param in model.named_parameters():
                param_devices.add(str(param.device))
                # So s√°nh device type thay v√¨ exact device
                if param.device.type != self.device.type:
                    print(f"‚ùå {name} parameter {param_name}: {param.device} (expected {self.device})")
                    all_consistent = False
            
            # Ki·ªÉm tra buffers
            buffer_devices = set()
            for buffer_name, buffer in model.named_buffers():
                if hasattr(buffer, 'device'):
                    buffer_devices.add(str(buffer.device))
                    # So s√°nh device type thay v√¨ exact device
                    if buffer.device.type != self.device.type:
                        print(f"‚ùå {name} buffer {buffer_name}: {buffer.device} (expected {self.device})")
                        all_consistent = False
            
            print(f"‚úÖ {name}: params={param_devices}, buffers={buffer_devices}")
        
        if all_consistent:
            print("üéâ All models are on the correct device!")
        else:
            print("‚ö†Ô∏è Device inconsistency detected - forcing models to device...")
            self.ensure_models_on_device()
    
    def evaluate_all_lambdas(self):
        """Evaluate t·∫•t c·∫£ lambda values"""
        lambda_values = self.args.lambdas
        
        for lambda_val in lambda_values:
            result = self.evaluate_lambda(lambda_val)
            self.results.append(result)
            
            print(f"Œª={lambda_val}: PSNR={result['psnr_db']:.2f}dB, "
                  f"MS-SSIM={result['ms_ssim']:.4f}, BPP={result['bpp']:.4f}")
    
    def save_results(self):
        """Save results to CSV"""
        if not self.results:
            print("No results to save!")
            return
        
        df = pd.DataFrame(self.results)
        df['dataset'] = self.args.dataset
        df['split'] = self.args.split
        df['image_size'] = self.args.image_size
        
        os.makedirs(os.path.dirname(self.args.output_csv), exist_ok=True)
        df.to_csv(self.args.output_csv, index=False)
        
        print(f"‚úì Results saved to {self.args.output_csv}")
        print("\n" + "="*50)
        print("CODEC EVALUATION SUMMARY")
        print("="*50)
        print(df.to_string(index=False))
        print("="*50)


def main():
    parser = argparse.ArgumentParser(description='Codec Metrics Evaluation - Final Version')
    
    # Model checkpoints
    parser.add_argument('--stage1_checkpoint', type=str, default='checkpoints/stage1_wavelet_coco_best.pth',
                       help='Path to Stage 1 checkpoint (WaveletTransformCNN)')
    parser.add_argument('--stage2_checkpoint', type=str, default='checkpoints/stage2_compressor_coco_lambda128_best.pth',
                       help='Path to Stage 2 checkpoint (CompressorVNVC)')
    
    # Dataset arguments
    parser.add_argument('--dataset', type=str, choices=['coco', 'davis'], default='coco',
                       help='Dataset to evaluate')
    parser.add_argument('--data_dir', type=str, default='datasets/COCO',
                       help='Dataset directory')
    parser.add_argument('--split', type=str, default='val',
                       help='Dataset split')
    parser.add_argument('--image_size', type=int, default=256,
                       help='Input image size')
    
    # Evaluation arguments
    parser.add_argument('--lambdas', type=int, nargs='+', default=[128],
                       help='Lambda values to evaluate')
    parser.add_argument('--batch_size', type=int, default=1,
                       help='Batch size')
    parser.add_argument('--max_samples', type=int, default=None,
                       help='Maximum samples to evaluate')
    
    # Output arguments
    parser.add_argument('--output_csv', type=str, default='results/codec_metrics_final.csv',
                       help='Output CSV file')
    
    args = parser.parse_args()
    
    # Create evaluator v√† run evaluation
    evaluator = CodecEvaluatorFinal(args)
    evaluator.evaluate_all_lambdas()
    evaluator.save_results()


if __name__ == '__main__':
    main() 