#!/bin/bash

# =============================================================================
# WAVENET-MV FULL TRAINING PIPELINE SCRIPT FOR SERVER
# =============================================================================
# Script n√†y ch·∫°y to√†n b·ªô qu√° tr√¨nh training t·ª´ stage 1 ƒë·∫øn stage 3
# v√† evaluation tr√™n server
# =============================================================================

# Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng
echo -e "\nüîß SETTING UP ENVIRONMENT"
echo "----------------------------------------"

# Ki·ªÉm tra CUDA
nvidia-smi
if [ $? -ne 0 ]; then
    echo "‚ùå CUDA kh√¥ng kh·∫£ d·ª•ng! Vui l√≤ng ki·ªÉm tra c√†i ƒë·∫∑t GPU."
    exit 1
fi

# C√†i ƒë·∫∑t dependencies n·∫øu c·∫ßn
pip install -r requirements.txt

# T·∫°o th∆∞ m·ª•c checkpoints v√† results n·∫øu ch∆∞a t·ªìn t·∫°i
mkdir -p checkpoints
mkdir -p results

# =============================================================================
# STAGE 1: TRAIN WAVELET MODEL
# =============================================================================
echo -e "\nüîÑ STARTING STAGE 1: WAVELET TRAINING"
echo "----------------------------------------"

python training/stage1_train_wavelet.py \
    --epochs 100 \
    --batch_size 16 \
    --learning_rate 1e-4 \
    --dataset coco \
    --data_dir datasets/COCO \
    --resume checkpoints/stage1_wavelet_coco_latest.pth

if [ $? -ne 0 ]; then
    echo "‚ùå Stage 1 training th·∫•t b·∫°i"
    exit 1
fi

echo "‚úÖ Stage 1 ho√†n th√†nh th√†nh c√¥ng"

# =============================================================================
# STAGE 2: TRAIN COMPRESSOR MODEL v·ªõi nhi·ªÅu lambda values
# =============================================================================
echo -e "\nüîÑ STARTING STAGE 2: COMPRESSOR TRAINING"
echo "----------------------------------------"

# Danh s√°ch lambda values ƒë·ªÉ train
lambda_values=(64 128 256 512 1024 2048)

for lambda in "${lambda_values[@]}"; do
    echo -e "\nüîÑ Training compressor v·ªõi lambda = $lambda"
    
    python training/stage2_train_compressor.py \
        --epochs 100 \
        --batch_size 8 \
        --learning_rate 1e-4 \
        --dataset coco \
        --data_dir datasets/COCO \
        --stage1_checkpoint checkpoints/stage1_wavelet_coco_best.pth \
        --lambda_rd $lambda \
        --resume checkpoints/stage2_compressor_coco_lambda${lambda}_latest.pth
    
    if [ $? -ne 0 ]; then
        echo "‚ùå Stage 2 training th·∫•t b·∫°i v·ªõi lambda = $lambda"
        continue
    fi
    
    echo "‚úÖ Stage 2 ho√†n th√†nh th√†nh c√¥ng v·ªõi lambda = $lambda"
done

# =============================================================================
# STAGE 3: TRAIN AI HEADS
# =============================================================================
echo -e "\nüîÑ STARTING STAGE 3: AI HEADS TRAINING"
echo "----------------------------------------"

# S·ª≠ d·ª•ng lambda=256 l√†m default
python training/stage3_train_ai.py \
    --epochs 50 \
    --batch_size 8 \
    --learning_rate 2e-4 \
    --dataset coco \
    --data_dir datasets/COCO \
    --stage1_checkpoint checkpoints/stage1_wavelet_coco_best.pth \
    --stage2_checkpoint checkpoints/stage2_compressor_coco_lambda256_best.pth \
    --lambda_rd 256 \
    --enable_detection \
    --enable_segmentation \
    --resume checkpoints/stage3_ai_heads_coco_latest.pth

if [ $? -ne 0 ]; then
    echo "‚ùå Stage 3 training th·∫•t b·∫°i"
    exit 1
fi

echo "‚úÖ Stage 3 ho√†n th√†nh th√†nh c√¥ng"

# =============================================================================
# EVALUATION: ƒê√°nh gi√° m√¥ h√¨nh
# =============================================================================
echo -e "\nüîÑ RUNNING COMPREHENSIVE EVALUATION"
echo "----------------------------------------"

# T·∫°o th∆∞ m·ª•c k·∫øt qu·∫£ n·∫øu ch∆∞a t·ªìn t·∫°i
mkdir -p results

# Ch·∫°y ƒë√°nh gi√° cho t·∫•t c·∫£ lambda values ƒë√£ train
for lambda in "${lambda_values[@]}"; do
    echo -e "\nüîÑ Evaluating model v·ªõi lambda = $lambda"
    
    python evaluation/codec_metrics_final.py \
        --stage1_checkpoint checkpoints/stage1_wavelet_coco_best.pth \
        --stage2_checkpoint checkpoints/stage2_compressor_coco_lambda${lambda}_best.pth \
        --stage3_checkpoint checkpoints/stage3_ai_heads_coco_best.pth \
        --dataset coco \
        --data_dir datasets/COCO \
        --split val \
        --max_samples 100 \
        --batch_size 4 \
        --output_file results/wavenet_mv_lambda${lambda}_evaluation.csv
    
    if [ $? -ne 0 ]; then
        echo "‚ùå Evaluation th·∫•t b·∫°i v·ªõi lambda = $lambda"
        continue
    fi
    
    echo "‚úÖ Evaluation ho√†n th√†nh v·ªõi lambda = $lambda"
done

# =============================================================================
# GENERATE REPORTS: T·∫°o b√°o c√°o t·ªïng h·ª£p
# =============================================================================
echo -e "\nüîÑ GENERATING COMPREHENSIVE REPORTS"
echo "----------------------------------------"

# T·∫°o b√°o c√°o t·ªïng h·ª£p t·ª´ c√°c k·∫øt qu·∫£ ƒë√°nh gi√°
python evaluation/generate_summary_report.py \
    --input_dir results \
    --output_file results/wavenet_mv_comprehensive_results.csv

if [ $? -ne 0 ]; then
    echo "‚ùå Report generation th·∫•t b·∫°i"
    exit 1
fi

echo "‚úÖ Report generation ho√†n th√†nh th√†nh c√¥ng"

# =============================================================================
# SUMMARY: T√≥m t·∫Øt k·∫øt qu·∫£
# =============================================================================
echo -e "\nüéâ FULL TRAINING PIPELINE COMPLETED!"
echo "üìä Results saved in results/ directory"
echo "üìà TensorBoard logs in runs/ directory"
echo "üíæ Checkpoints saved in checkpoints/ directory"

# In danh s√°ch checkpoints
echo -e "\nüìã AVAILABLE CHECKPOINTS:"
ls -la checkpoints/

# In k·∫øt qu·∫£ m·∫´u
echo -e "\nüìä EVALUATION RESULTS PREVIEW:"
head -n 5 results/wavenet_mv_comprehensive_results.csv

echo -e "\n‚úÖ TRAINING PIPELINE HO√ÄN TH√ÄNH!" 