#!/bin/bash

# =============================================================================
# COMPREHENSIVE EVALUATION: COMPRESSION + AI ACCURACY
# =============================================================================
# Script nÃ y cháº¡y Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n bao gá»“m:
# 1. JPEG/JPEG2000 compression metrics (PSNR, SSIM, BPP)
# 2. AI task performance (object detection, segmentation)
# 3. WAVENET-MV comparison (náº¿u cÃ³)
# =============================================================================

echo -e "\nğŸ”§ COMPREHENSIVE COMPRESSION + AI ACCURACY EVALUATION"
echo "======================================================="

# Kiá»ƒm tra mÃ´i trÆ°á»ng
echo "Checking environment..."
python3 --version
if [ $? -ne 0 ]; then
    echo "âŒ Python3 khÃ´ng kháº£ dá»¥ng!"
    exit 1
fi

# Kiá»ƒm tra dataset
DATASET_DIR="datasets/COCO"
if [ ! -d "$DATASET_DIR" ]; then
    echo "âŒ Dataset not found at $DATASET_DIR"
    echo "Please run: python datasets/setup_coco_official.py"
    exit 1
fi

if [ ! -d "$DATASET_DIR/val2017" ]; then
    echo "âŒ val2017 directory not found"
    echo "Please setup COCO dataset first"
    exit 1
fi

echo "âœ… Dataset found: $DATASET_DIR"

# CÃ i Ä‘áº·t dependencies
echo "Installing dependencies..."
pip3 install -q opencv-contrib-python pillow tqdm pandas scikit-image pathlib2 pillow-heif imageio
pip3 install -q ultralytics  # YOLOv8
pip3 install -q segmentation-models-pytorch  # Segmentation models
pip3 install -q torch torchvision  # PyTorch

# Kiá»ƒm tra GPU
python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# Táº¡o results directory
mkdir -p results
mkdir -p results/comprehensive_evaluation

# =============================================================================
# PHASE 1: COMPRESSION METRICS EVALUATION
# =============================================================================

echo -e "\nğŸ“Š PHASE 1: COMPRESSION METRICS EVALUATION"
echo "-------------------------------------------"

# Cháº¡y evaluation compression cÆ¡ báº£n trÆ°á»›c
echo "Running compression metrics evaluation..."
python3 server_jpeg_evaluation.py \
    --data_dir "$DATASET_DIR" \
    --max_images 100 \
    --quality_levels 10 20 30 40 50 60 70 80 90 95 \
    --output_dir results/comprehensive_evaluation \
    --output_file compression_metrics.csv

if [ $? -ne 0 ]; then
    echo "âŒ Compression metrics evaluation failed"
    exit 1
fi

echo "âœ… Compression metrics completed"

# =============================================================================
# PHASE 2: AI ACCURACY EVALUATION
# =============================================================================

echo -e "\nğŸ¤– PHASE 2: AI ACCURACY EVALUATION"
echo "----------------------------------"

# Cháº¡y AI accuracy evaluation
echo "Running AI accuracy evaluation (this may take longer)..."
python3 evaluate_ai_accuracy.py \
    --data_dir "$DATASET_DIR" \
    --max_images 50 \
    --codecs JPEG JPEG2000 \
    --quality_levels 10 30 50 70 90 \
    --output_dir results/comprehensive_evaluation \
    --temp_dir temp_compressed

if [ $? -ne 0 ]; then
    echo "âš ï¸ AI accuracy evaluation had issues, but continuing..."
fi

echo "âœ… AI accuracy evaluation completed"

# =============================================================================
# PHASE 3: WAVENET-MV EVALUATION (if available)
# =============================================================================

echo -e "\nğŸš€ PHASE 3: WAVENET-MV EVALUATION"
echo "---------------------------------"

# Kiá»ƒm tra xem cÃ³ WAVENET-MV model khÃ´ng
if [ -f "models/wavenet_mv_trained.pth" ] || [ -f "checkpoints/best_model.pth" ]; then
    echo "Found WAVENET-MV model, running evaluation..."
    
    # Cháº¡y WAVENET-MV evaluation
    python3 evaluate_wavenet_mv.py \
        --data_dir "$DATASET_DIR" \
        --max_images 50 \
        --lambda_values 64 128 256 512 1024 2048 \
        --output_dir results/comprehensive_evaluation \
        --model_path checkpoints/best_model.pth
    
    if [ $? -eq 0 ]; then
        echo "âœ… WAVENET-MV evaluation completed"
    else
        echo "âš ï¸ WAVENET-MV evaluation failed"
    fi
else
    echo "âš ï¸ WAVENET-MV model not found, skipping evaluation"
    echo "To include WAVENET-MV comparison:"
    echo "  1. Train WAVENET-MV model first"
    echo "  2. Save model to checkpoints/best_model.pth"
    echo "  3. Re-run this script"
fi

# =============================================================================
# PHASE 4: COMBINED ANALYSIS AND REPORTING
# =============================================================================

echo -e "\nğŸ“ˆ PHASE 4: COMBINED ANALYSIS"
echo "-----------------------------"

python3 -c "
import pandas as pd
import numpy as np
import os
from pathlib import Path

results_dir = Path('results/comprehensive_evaluation')

print('ğŸ“Š COMPREHENSIVE EVALUATION SUMMARY')
print('=' * 60)

# Load compression metrics
compression_file = results_dir / 'compression_metrics.csv'
if compression_file.exists():
    comp_df = pd.read_csv(compression_file)
    print(f'âœ… Compression metrics: {len(comp_df)} data points')
else:
    print('âŒ Compression metrics not found')
    comp_df = None

# Load AI accuracy metrics
ai_file = results_dir / 'ai_accuracy_evaluation.csv'
if ai_file.exists():
    ai_df = pd.read_csv(ai_file)
    print(f'âœ… AI accuracy metrics: {len(ai_df)} data points')
else:
    print('âŒ AI accuracy metrics not found')
    ai_df = None

# Load WAVENET-MV metrics (if available)
wavenet_file = results_dir / 'wavenet_mv_evaluation.csv'
if wavenet_file.exists():
    wavenet_df = pd.read_csv(wavenet_file)
    print(f'âœ… WAVENET-MV metrics: {len(wavenet_df)} data points')
else:
    print('âš ï¸ WAVENET-MV metrics not available')
    wavenet_df = None

print('\nğŸ“‹ DETAILED RESULTS:')
print('-' * 40)

# Analyze JPEG results
if ai_df is not None:
    jpeg_data = ai_df[ai_df['codec'] == 'JPEG']
    if not jpeg_data.empty:
        print('\nJPEG PERFORMANCE:')
        for quality in sorted(jpeg_data['quality'].unique()):
            q_data = jpeg_data[jpeg_data['quality'] == quality]
            avg_psnr = q_data['psnr'].mean()
            avg_ssim = q_data['ssim'].mean() 
            avg_bpp = q_data['bpp'].mean()
            avg_map = q_data['mAP'].mean()
            avg_miou = q_data['mIoU'].mean()
            
            # Handle infinite PSNR
            psnr_str = f'{avg_psnr:.2f}' if np.isfinite(avg_psnr) else 'inf'
            
            print(f'  Q={quality:2d}: PSNR={psnr_str:>6}dB, SSIM={avg_ssim:.3f}, '
                  f'BPP={avg_bpp:.3f}, mAP={avg_map:.3f}, mIoU={avg_miou:.3f}')

# Analyze JPEG2000 results
if ai_df is not None:
    jp2_data = ai_df[ai_df['codec'] == 'JPEG2000']
    if not jp2_data.empty:
        print('\nJPEG2000 PERFORMANCE:')
        for quality in sorted(jp2_data['quality'].unique()):
            q_data = jp2_data[jp2_data['quality'] == quality]
            avg_psnr = q_data['psnr'].mean()
            avg_ssim = q_data['ssim'].mean()
            avg_bpp = q_data['bpp'].mean() 
            avg_map = q_data['mAP'].mean()
            avg_miou = q_data['mIoU'].mean()
            
            psnr_str = f'{avg_psnr:.2f}' if np.isfinite(avg_psnr) else 'inf'
            
            print(f'  Q={quality:2d}: PSNR={psnr_str:>6}dB, SSIM={avg_ssim:.3f}, '
                  f'BPP={avg_bpp:.3f}, mAP={avg_map:.3f}, mIoU={avg_miou:.3f}')

# Analyze WAVENET-MV results (if available)
if wavenet_df is not None:
    print('\nWAVENET-MV PERFORMANCE:')
    for lambda_val in sorted(wavenet_df['lambda'].unique()):
        l_data = wavenet_df[wavenet_df['lambda'] == lambda_val]
        avg_psnr = l_data['psnr'].mean()
        avg_ssim = l_data['ssim'].mean()
        avg_bpp = l_data['bpp'].mean()
        avg_map = l_data['mAP'].mean()
        avg_miou = l_data['mIoU'].mean()
        
        print(f'  Î»={lambda_val:4d}: PSNR={avg_psnr:6.2f}dB, SSIM={avg_ssim:.3f}, '
              f'BPP={avg_bpp:.3f}, mAP={avg_map:.3f}, mIoU={avg_miou:.3f}')

print('\nğŸ’¡ ANALYSIS NOTES:')
print('- PSNR=inf indicates lossless compression (perfect reconstruction)')
print('- SSIM=1.0 indicates perfect structural similarity')
print('- Higher mAP = better object detection performance')
print('- Higher mIoU = better segmentation performance')
print('- Lower BPP = better compression efficiency')

# Generate combined CSV for paper
if ai_df is not None:
    print('\nğŸ“ Generating combined results for paper...')
    
    # Prepare data for paper table
    paper_results = []
    
    # JPEG results
    jpeg_data = ai_df[ai_df['codec'] == 'JPEG']
    for quality in sorted(jpeg_data['quality'].unique()):
        q_data = jpeg_data[jpeg_data['quality'] == quality]
        if not q_data.empty:
            paper_results.append({
                'Method': 'JPEG',
                'Setting': f'Q={quality}',
                'PSNR_dB': f'{q_data[\"psnr\"].mean():.1f} Â± {q_data[\"psnr\"].std():.1f}',
                'MS_SSIM': f'{q_data[\"ssim\"].mean():.3f} Â± {q_data[\"ssim\"].std():.3f}',
                'BPP': f'{q_data[\"bpp\"].mean():.3f} Â± {q_data[\"bpp\"].std():.3f}',
                'AI_Accuracy_mAP': f'{q_data[\"mAP\"].mean():.3f} Â± {q_data[\"mAP\"].std():.3f}'
            })
    
    # WAVENET-MV results (if available)
    if wavenet_df is not None:
        for lambda_val in sorted(wavenet_df['lambda'].unique()):
            l_data = wavenet_df[wavenet_df['lambda'] == lambda_val]
            if not l_data.empty:
                paper_results.append({
                    'Method': 'WAVENET-MV',
                    'Setting': f'Î»={lambda_val}',
                    'PSNR_dB': f'{l_data[\"psnr\"].mean():.1f} Â± {l_data[\"psnr\"].std():.1f}',
                    'MS_SSIM': f'{l_data[\"ssim\"].mean():.3f} Â± {l_data[\"ssim\"].std():.3f}',
                    'BPP': f'{l_data[\"bpp\"].mean():.3f} Â± {l_data[\"bpp\"].std():.3f}',
                    'AI_Accuracy_mAP': f'{l_data[\"mAP\"].mean():.3f} Â± {l_data[\"mAP\"].std():.3f}'
                })
    
    # Save paper results
    if paper_results:
        paper_df = pd.DataFrame(paper_results)
        paper_file = results_dir / 'paper_results_table.csv'
        paper_df.to_csv(paper_file, index=False)
        print(f'ğŸ“Š Paper results table saved: {paper_file}')
        
        # Show table preview
        print('\nğŸ“‹ PAPER TABLE PREVIEW:')
        print(paper_df.to_string(index=False))

print('\nâœ… Combined analysis completed!')
"

# =============================================================================
# FINAL SUMMARY
# =============================================================================

echo -e "\nğŸ‰ COMPREHENSIVE EVALUATION COMPLETED!"
echo "====================================="
echo "ğŸ“‚ Results location: results/comprehensive_evaluation/"
echo ""
echo "ğŸ“Š Generated files:"
ls -la results/comprehensive_evaluation/
echo ""
echo "âœ… Ready for paper results!"
echo ""
echo "ğŸ“ˆ Next steps:"
echo "  1. Use 'paper_results_table.csv' for LaTeX table"
echo "  2. Analyze AI accuracy vs compression trade-offs"
echo "  3. Compare WAVENET-MV vs traditional codecs"
echo "  4. Generate rate-distortion curves" 