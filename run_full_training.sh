#!/bin/bash
# Run Full WAVENET-MV Training Pipeline
# Cháº¡y toÃ n bá»™ 3 stages vá»›i táº¥t cáº£ lambda values

echo "ğŸš€ RUNNING FULL WAVENET-MV TRAINING PIPELINE"
echo "============================================"

# Check if we're on the server (has CUDA)
if ! command -v nvidia-smi &> /dev/null; then
    echo "âŒ This script must be run on Ubuntu server with CUDA"
    echo "Current machine doesn't have NVIDIA GPU"
    exit 1
fi



# Create directories
mkdir -p checkpoints
mkdir -p runs
mkdir -p results

# Stage 1: Train WaveletTransformCNN
echo "ğŸ”„ STAGE 1: TRAINING WAVELETTRANSFORMCNN"
echo "----------------------------------------"

python training/stage1_train_wavelet.py \
    --epochs 30 \
    --batch_size 8 \
    --learning_rate 2e-4 \
    --dataset coco \
    --data_dir datasets/COCO \
    --resume checkpoints/stage1_wavelet_coco_best.pth

if [ $? -ne 0 ]; then
    echo "âŒ Stage 1 training failed"
    exit 1
fi

echo "âœ… Stage 1 completed successfully"

# Stage 2: Train CompressorVNVC with multiple lambda values
echo -e "\nğŸ”„ STAGE 2: TRAINING COMPRESSORVNVC"
echo "----------------------------------------"

# Lambda values based on memory [[memory:645488]]
LAMBDA_VALUES=(64 128 256 512 1024 2048 4096)

for lambda in "${LAMBDA_VALUES[@]}"; do
    echo "ğŸ”„ Training with Î» = $lambda"
    
    python training/stage2_train_compressor.py \
        --epochs 40 \
        --batch_size 8 \
        --learning_rate 2e-4 \
        --dataset coco \
        --data_dir datasets/COCO \
        --lambda_rd ${lambda} \
        --wavelet_checkpoint checkpoints/stage1_wavelet_coco_best.pth \
        --resume checkpoints/stage2_compressor_coco_lambda${lambda}_best.pth
    
    if [ $? -ne 0 ]; then
        echo "âŒ Stage 2 training failed for Î» = $lambda"
        exit 1
    fi
    
    echo "âœ… Stage 2 completed for Î» = $lambda"
done

# Stage 3: Train AI Heads
echo -e "\nğŸ”„ STAGE 3: TRAINING AI HEADS"
echo "----------------------------------------"

# Train with best lambda from Stage 2 (will be determined by evaluation)
python training/stage3_train_ai.py \
    --epochs 50 \
    --batch_size 8 \
    --learning_rate 2e-4 \
    --dataset coco \
    --data_dir datasets/COCO \
    --wavelet_checkpoint checkpoints/stage1_wavelet_coco_best.pth \
    --compressor_checkpoint checkpoints/stage2_compressor_coco_lambda256_best.pth \
    --resume checkpoints/stage3_ai_heads_coco_best.pth

if [ $? -ne 0 ]; then
    echo "âŒ Stage 3 training failed"
    exit 1
fi

echo "âœ… Stage 3 completed successfully"

# Run evaluation for all checkpoints
echo -e "\nğŸ”„ RUNNING FULL EVALUATION"
echo "----------------------------------------"

python generate_paper_results.py \
    --checkpoint checkpoints/stage3_ai_heads_coco_best.pth \
    --dataset coco \
    --data_dir datasets/COCO \
    --split val \
    --max_samples 500 \
    --batch_size 4

if [ $? -ne 0 ]; then
    echo "âŒ Evaluation failed"
    exit 1
fi

echo "âœ… Evaluation completed successfully"

echo -e "\nğŸ‰ FULL TRAINING PIPELINE COMPLETED!"
echo "ğŸ“Š Results saved in results/ directory"
echo "ğŸ“ˆ TensorBoard logs in runs/ directory"
echo "ğŸ’¾ Checkpoints saved in checkpoints/ directory"

# Print available checkpoints
echo -e "\nğŸ“‹ AVAILABLE CHECKPOINTS:"
ls -la checkpoints/

# Print sample results
echo -e "\nğŸ“Š EVALUATION RESULTS:"
head -n 5 results/wavenet_mv_full_evaluation.csv 